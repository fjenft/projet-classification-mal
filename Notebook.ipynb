{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"font-size: 48px; color: red;\">Classification à partir de la base de données My Anime List</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"font-size: 32px; color: green;\">Partie I : Récupération des données à partir de l'API de MyAnimeList puis nettoyage des données</h1>\n",
    "\n",
    "Cliquez [ici](https://myanimelist.net/apiconfig/references/api/v2) pour accéder au site de l'API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"font-size: 22px; color: blue;\">1/Récupération des données à partir de l'API de MyAnimeList</h1>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 collected for the moment...\n",
      "200 collected for the moment...\n",
      "300 collected for the moment...\n",
      "400 collected for the moment...\n",
      "500 collected for the moment...\n",
      "600 collected for the moment...\n",
      "700 collected for the moment...\n",
      "800 collected for the moment...\n",
      "900 collected for the moment...\n",
      "1000 collected for the moment...\n",
      "1100 collected for the moment...\n",
      "1200 collected for the moment...\n",
      "1300 collected for the moment...\n",
      "1400 collected for the moment...\n",
      "1500 collected for the moment...\n",
      "1600 collected for the moment...\n",
      "1700 collected for the moment...\n",
      "1800 collected for the moment...\n",
      "1900 collected for the moment...\n",
      "2000 collected for the moment...\n",
      "2100 collected for the moment...\n",
      "2200 collected for the moment...\n",
      "2300 collected for the moment...\n",
      "2400 collected for the moment...\n",
      "2500 collected for the moment...\n",
      "2600 collected for the moment...\n",
      "2700 collected for the moment...\n",
      "2800 collected for the moment...\n",
      "2900 collected for the moment...\n",
      "3000 collected for the moment...\n",
      "3100 collected for the moment...\n",
      "3200 collected for the moment...\n",
      "3300 collected for the moment...\n",
      "3400 collected for the moment...\n",
      "3500 collected for the moment...\n",
      "3600 collected for the moment...\n",
      "3700 collected for the moment...\n",
      "3800 collected for the moment...\n",
      "3900 collected for the moment...\n",
      "4000 collected for the moment...\n",
      "4100 collected for the moment...\n",
      "4200 collected for the moment...\n",
      "4300 collected for the moment...\n",
      "4400 collected for the moment...\n",
      "4500 collected for the moment...\n",
      "4600 collected for the moment...\n",
      "4700 collected for the moment...\n",
      "4800 collected for the moment...\n",
      "4900 collected for the moment...\n",
      "5000 collected for the moment...\n",
      "5100 collected for the moment...\n",
      "5200 collected for the moment...\n",
      "5300 collected for the moment...\n",
      "5400 collected for the moment...\n",
      "5500 collected for the moment...\n",
      "5600 collected for the moment...\n",
      "5700 collected for the moment...\n",
      "5800 collected for the moment...\n",
      "5900 collected for the moment...\n",
      "6000 collected for the moment...\n",
      "6100 collected for the moment...\n",
      "6200 collected for the moment...\n",
      "6300 collected for the moment...\n",
      "6400 collected for the moment...\n",
      "6500 collected for the moment...\n",
      "6600 collected for the moment...\n",
      "6700 collected for the moment...\n",
      "6800 collected for the moment...\n",
      "6900 collected for the moment...\n",
      "7000 collected for the moment...\n",
      "7100 collected for the moment...\n",
      "7200 collected for the moment...\n",
      "7300 collected for the moment...\n",
      "7400 collected for the moment...\n",
      "7500 collected for the moment...\n",
      "7600 collected for the moment...\n",
      "7700 collected for the moment...\n",
      "7800 collected for the moment...\n",
      "7900 collected for the moment...\n",
      "8000 collected for the moment...\n",
      "8100 collected for the moment...\n",
      "8200 collected for the moment...\n",
      "8300 collected for the moment...\n",
      "8400 collected for the moment...\n",
      "8500 collected for the moment...\n",
      "8600 collected for the moment...\n",
      "8700 collected for the moment...\n",
      "8800 collected for the moment...\n",
      "8900 collected for the moment...\n",
      "9000 collected for the moment...\n",
      "9100 collected for the moment...\n",
      "9200 collected for the moment...\n",
      "9300 collected for the moment...\n",
      "9400 collected for the moment...\n",
      "9500 collected for the moment...\n",
      "9600 collected for the moment...\n",
      "9700 collected for the moment...\n",
      "9800 collected for the moment...\n",
      "9900 collected for the moment...\n",
      "10000 collected for the moment...\n",
      "10100 collected for the moment...\n",
      "10200 collected for the moment...\n",
      "10300 collected for the moment...\n",
      "10400 collected for the moment...\n",
      "10500 collected for the moment...\n",
      "10600 collected for the moment...\n",
      "10700 collected for the moment...\n",
      "10800 collected for the moment...\n",
      "10900 collected for the moment...\n",
      "11000 collected for the moment...\n",
      "11100 collected for the moment...\n",
      "11200 collected for the moment...\n",
      "11300 collected for the moment...\n",
      "11400 collected for the moment...\n",
      "11500 collected for the moment...\n",
      "11600 collected for the moment...\n",
      "11700 collected for the moment...\n",
      "11800 collected for the moment...\n",
      "11900 collected for the moment...\n",
      "12000 collected for the moment...\n",
      "12100 collected for the moment...\n",
      "12200 collected for the moment...\n",
      "12300 collected for the moment...\n",
      "12400 collected for the moment...\n",
      "12500 collected for the moment...\n",
      "12600 collected for the moment...\n",
      "12700 collected for the moment...\n",
      "12800 collected for the moment...\n",
      "12900 collected for the moment...\n",
      "13000 collected for the moment...\n",
      "13100 collected for the moment...\n",
      "13200 collected for the moment...\n",
      "13300 collected for the moment...\n",
      "13400 collected for the moment...\n",
      "13500 collected for the moment...\n",
      "13600 collected for the moment...\n",
      "13700 collected for the moment...\n",
      "13800 collected for the moment...\n",
      "13900 collected for the moment...\n",
      "14000 collected for the moment...\n",
      "14100 collected for the moment...\n",
      "14200 collected for the moment...\n",
      "14300 collected for the moment...\n",
      "14400 collected for the moment...\n",
      "14500 collected for the moment...\n",
      "14600 collected for the moment...\n",
      "14700 collected for the moment...\n",
      "14800 collected for the moment...\n",
      "14900 collected for the moment...\n",
      "15000 collected for the moment...\n",
      "15100 collected for the moment...\n",
      "15200 collected for the moment...\n",
      "15300 collected for the moment...\n",
      "15400 collected for the moment...\n",
      "15500 collected for the moment...\n",
      "15600 collected for the moment...\n",
      "15700 collected for the moment...\n",
      "15800 collected for the moment...\n",
      "15900 collected for the moment...\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "#Comme l'API ne nous permet pas de récupérer les animes en groupe à travers leur ID, on récupère la liste des animés et leur caractéristiques à partir de leur le rang, dans l'ordre décroissant décroissant (en prenant les 100 1ers rangs, puis les 100 rangs suivants ainsi de suite...)\n",
    "\n",
    "all_anime = [] \n",
    "nbr_needed = 27490  #Total number of anime on MAL as of 13/11/2024 (obtained by looking directly on the site of myanimelist)\n",
    "\n",
    "ID = {'X-MAL-CLIENT-ID': 'c2db532c391bf31339ffd6afa650d528'} #id client obtenu après s'être inscrit sur My Anime List et avoir fait une demande\n",
    "url = 'https://api.myanimelist.net/v2/anime/ranking'\n",
    "parameters = {\n",
    "    'ranking_type': 'all',  \n",
    "    'limit': 100,  # Max limit per request, divides the total number of anime on mal\n",
    "    'fields': 'id,title,mean,start_date,end_date,rank,popularity,num_list_users,num_scoring_users,nsfw,media_type,status,num_episodes,start_season,broadcast,source,average_episode_duration,rating'\n",
    "}\n",
    "\n",
    "k = 0  # offset but also the number of times the loop is used that is 27490/100 here\n",
    "\n",
    "# Loop until we've collected the target number of anime\n",
    "while k < nbr_needed:\n",
    "    parameters['offset'] = k\n",
    "    mal = requests.get(url, headers=ID, params=parameters)\n",
    "\n",
    "    \n",
    "    if mal.status_code == 200: # Check if the request is successful\n",
    "        data = mal.json()\n",
    "        all_anime.extend(data['data'])\n",
    "        k += parameters['limit']\n",
    "\n",
    "        print(str(len(all_anime)) + \" collected for the moment...\")\n",
    "    \n",
    "        if len(all_anime) >= nbr_needed:\n",
    "            print(\"the total number of anime collected is \" + str(len(all_anime)))\n",
    "            break\n",
    "    else :\n",
    "        print(\"cannot retrieve more than \" + str(len(all_anime))) \n",
    "        break\n",
    "\n",
    "anime_data = pd.DataFrame(all_anime) \n",
    "print(anime_data.head(2))\n",
    "\n",
    "print(anime_data.head())\n",
    "print(anime_data.info())\n",
    "\n",
    "#On voit que le dataframe est constitué du rang des animé et d'un \"node\", un dictionnaire qui contient toutes les caractéristiques de chaque anime.\n",
    "#Il faut donc extraire chaque élément du dictionnaire node pour en faire des colonnes à part entière\n",
    "\n",
    "# On extrait toutes les clés du dictionnaire 'node' et on les transforme en colonnes du dataframe\n",
    "anime_data['node'] = anime_data['node'].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else x)    \n",
    "keys = set().union(*(d.keys() for d in anime_data['node'] if isinstance(d, dict)))\n",
    "for y in keys:\n",
    "    anime_data[f'{y}'] = anime_data['node'].apply(lambda x: x.get(y) if isinstance(x, dict) else None)\n",
    "\n",
    "# On convertit les colonnes contenant des dictionnaires en chaînes\n",
    "for column in anime_data.columns:\n",
    "    if anime_data[column].map(type).eq(dict).any():\n",
    "        anime_data[column] = anime_data[column].apply(lambda x: str(x) if isinstance(x, dict) else x)\n",
    "\n",
    "print(anime_data.head())\n",
    "\n",
    "#On supprime la colonne node qui n'apporte plus d'info\n",
    "anime_data = anime_data.drop(columns=['node'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"font-size: 22px; color: blue;\">2/Nettoyage des données et enregistrement du dataframe en fichier csv</h1>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'anime_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#On vérifie s'il y a des doublons\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m nbr_doublons \u001b[38;5;241m=\u001b[39m \u001b[43manime_data\u001b[49m\u001b[38;5;241m.\u001b[39mduplicated()\u001b[38;5;241m.\u001b[39msum()\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIl y a \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnbr_doublons\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m doublons\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m#On supprime les colonnes qui ne serviront pas pour la recommendation\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'anime_data' is not defined"
     ]
    }
   ],
   "source": [
    "#On vérifie s'il y a des doublons\n",
    "nbr_doublons = anime_data.duplicated().sum()\n",
    "print(f\"Il y a {nbr_doublons} doublons\")\n",
    "\n",
    "#On supprime les colonnes qui ne serviront pas pour la recommendation\n",
    "anime_data=anime_data.drop(columns=['main_picture','broadcast','start_season','end_date'],axis=1)\n",
    "pd.set_option('display.max_columns', None)\n",
    "print(anime_data.head())\n",
    "\n",
    "#On regarde combien de valeurs NaN il y a dans chaque colonne\n",
    "for i in anime_data.columns:\n",
    "    k = anime_data[i].isna().sum()\n",
    "    print(f\"Le nombre de NaN dans la colonne '{i}' est : {k}\")\n",
    "\n",
    "#On gère les différents types de NaN\n",
    "anime_data['source'] = anime_data['source'].fillna('source_inconnue')\n",
    "anime_data['rating'] = anime_data['source'].fillna('rating_inconnu')\n",
    "anime_data['mean'] = anime_data['mean'].fillna(0)\n",
    "anime_data = anime_data.dropna(subset=['rank'])\n",
    "\n",
    "#On veut uniquement garder l'année dans la colonne start_date\n",
    "anime_data['start_date'] = pd.to_datetime(anime_data['start_date'], errors='coerce')  \n",
    "anime_data['start_year'] = anime_data['start_date'].dt.year  \n",
    "anime_data=anime_data.drop(columns=['start_date'],axis=1)\n",
    "\n",
    "anime_data = anime_data.dropna(subset=['start_year'])\n",
    "\n",
    "#On vérifie qu'il n'y a plus de NaN\n",
    "nbr_nan = anime_data.isna().sum().sum()\n",
    "print(f\"Il reste {nbr_nan} NaN\")\n",
    "\n",
    "#On ne garde que les colonnes numériques pour calculer la matrice de correlation\n",
    "anime_data_num = anime_data.select_dtypes(include=[\"number\"])\n",
    "# Calcul de la matrice de corrélation\n",
    "print(anime_data_num.corr())\n",
    "\n",
    "#On sauvegarde le DataFrame en fichier CSV local\n",
    "local_file_path = \"anime_data.csv\"\n",
    "anime_data.to_csv(local_file_path, index=False)\n",
    "print(f\"Fichier CSV sauvegardé localement : {local_file_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"font-size: 32px; color: green;\">Partie II : Etudes des données et quelques visualisations</h1>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"font-size: 22px; color: blue;\">1/Familiarisation avec les données</h1>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#On cherche à voir à quoi ressemble les données obtenues sur les animés\n",
    "print(anime_data.head())\n",
    "print(anime_data.describe())\n",
    "print(anime_data.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#On regarde la matrice de corrélation\n",
    "\n",
    "numerical_features = ['num_list_users', 'num_episodes', 'mean', 'rank', 'popularity', 'num_scoring_users', 'start_year']\n",
    "plt.figure(figsize=(12, 8))\n",
    "correlation_matrix = df[numerical_features].corr()\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f')\n",
    "plt.title('Matrice de correlation')\n",
    "plt.show()\n",
    "plt.savefig('matrice_de_co.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"font-size: 22px; color: blue;\">2/Etude approfondie des données</h1>\n",
    "\n",
    "On cherche ici à tester et visualiser quelques intuitions qu'on pourrait avoir vis-à-vis des données\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#On va utiliser la caractéristique note moyenne des utilisateurs pour un animé dans nos études\n",
    "#Or, comme une note moyenne des utilisateurs pour un anime donné était mise à 0 quand elle était inconnue (NaN), on va supprimer les animes dont la note moyenne est 0.\n",
    "#De manière intuitive, il est normal de supprimer ces animes car une note moyenne par les utilisateurs de 0 est quasi impossible\n",
    "\n",
    "print(anime_data['mean'].describe()) #On voit bien une surreprésentation des animés avec une note moyenne des utilisateurs de 0\n",
    "\n",
    "anime_data_for_score=anime_data[anime_data['mean'] !=0] #On vient de créer un dataframe qui ne prendra pas en compte les animés avec une note moyenne des utilisateurs de 0 lorsqu'on utilisera cette même caractéristique.\n",
    "print(anime_data_for_score['mean'].describe())\n",
    "\n",
    "anime_data['start_year'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1/On pense que la distribution du nombre d'animés en fonction de leur note moyenne est une courbe en cloche centré autour de 5. \n",
    "#Pour vérifier cette hypothèse, on fait un histogramme qui représente le nombre d'animes par note moyenne.\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(anime_data_for_score['mean'], bins=30, kde=True, color='blue')\n",
    "plt.title(\"Distribution des animes en fonction de leurs notes moyennes\")\n",
    "plt.xlabel(\"Note moyenne\")\n",
    "plt.ylabel(\"Nbr d'animes\")\n",
    "plt.savefig(\"Nbr_animés_par_note_moyenne.png\")\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2/On pense que la production d'animés n'a cessé d'augmenter avec le temps. \n",
    "#Pour vérifier notre intuition, on représente l'évolution du nombre d'animes produits par année à l'aide d'un histogramme\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.countplot(x='start_year', data=anime_data, palette='viridis', hue='start_year', legend=False)\n",
    "plt.xticks(rotation=90)\n",
    "plt.title(\"Nombre d'animes produits par année\")\n",
    "plt.xlabel(\"Année de sortie\")\n",
    "plt.ylabel(\"Nbr d'animés\")\n",
    "plt.savefig(\"Nbr_animés_par_annee.png\")\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3/On veut savoir si une source est plus prolifique en animes que d'autres. \n",
    "#Pour cela, on créé un histogramme qui représente le nombre d'animes en fonction de la source dont ils sont inspirés\n",
    "plt.figure(figsize=(10, 6))\n",
    "source_counts = anime_data['source'].value_counts()\n",
    "sns.barplot(x=source_counts.index, y=source_counts.values, palette='coolwarm', hue=source_counts.index, legend=False)\n",
    "plt.xticks(rotation=90)\n",
    "plt.title(\"Nbr d'animes par sources'\")\n",
    "plt.xlabel(\"Source\")\n",
    "plt.ylabel(\"Nombre d'animés\")\n",
    "plt.savefig(\"Nbr_animes_par_source.png\")\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4/On veut savoir si une source est plus susceptibles de produire des animés bien notés que d'autres. \n",
    "#Pour cela on fait un histogramme qui représente la note moyenne des animés d'une même source en fonction de cette source.\n",
    "mean_scores_by_source = anime_data_for_score.groupby('source')['mean'].mean().sort_values(ascending=False)\n",
    "plt.figure(figsize=(12, 6))\n",
    "mean_scores_by_source.plot(kind='bar', color='skyblue')\n",
    "plt.title(\"Notes moyennes par source\")\n",
    "plt.xlabel(\"Source\")\n",
    "plt.ylabel(\"Note moyenne\")\n",
    "plt.savefig(\"Notes_moyennes_par_source.png\")\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5/On veut savoir si le nombre d'utilisateurs qui a noté un anime en particulier influence la note moyenne de cette animé. \n",
    "#Pour voir cela, on fait un nuage de points dont les points sont la note moyenne d'un anime en fonction du nombre d'utilisateurs qui ont noté cette animé.\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x='num_list_users', y='mean', data=anime_data_for_score, alpha=0.6)\n",
    "plt.title(\"Relation entre le nombre d'utilisateurs et la note moyenne\")\n",
    "plt.xlabel(\"Nombre d'utilisateurs ayant noté\")\n",
    "plt.ylabel(\"Note moyenne\")\n",
    "plt.xscale('log')  # On utilise une échelle logarithmique pour mieux visualiser\n",
    "plt.savefig(\"relation_ entre_nbr_utilisateurs_et_notes_moyennes.png\")\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#6/On veut comparer le score moyen des animes regroupés par rang (par exemple : rang 1 à 100 puis rang 101 à 200, etc,...).\n",
    "#Pour cela, on va créer 10 groupes de 100 animés\n",
    "\n",
    "anime_data_for_score['Groupe'] = (anime_data_for_score['rank'] - 1) // 100 + 1 #on créé les groupes de 100 animés\n",
    "anime_1000 = anime_data_for_score[anime_data_for_score['Groupe'] <= 10] #on ne garde que les 10 premiers groupes\n",
    "\n",
    "grouped_means = anime_1000.groupby('Groupe')['mean'].mean().reset_index()\n",
    "grouped_means['Groupe'] = grouped_means['Groupe'].astype(str)  # Conversion pour le graphique\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(x='Groupe', y='mean', data=grouped_means, palette='viridis')\n",
    "plt.title(\"Scores moyens des animes par groupe de rangs (sans scores nuls)\")\n",
    "plt.xlabel(\"Groupe de rangs (par 100)\")\n",
    "plt.ylabel(\"Score moyen\")\n",
    "plt.savefig(\"scores_moyens_par_100_rangs.png\")\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#7/On veut voir si animés sont mieux notés d'une année sur l'autre. \n",
    "#Pour cela, on fait un courbe dont chaque point est la moyenne des notes moyennes des animés d'une année en fonction de l'année\n",
    "mean_score_by_year = anime_data_for_score.groupby('start_year')['mean'].mean()\n",
    "plt.figure(figsize=(12, 6))\n",
    "mean_score_by_year.plot(kind='line', color='green', marker='o')\n",
    "plt.title(\"Évolution des notes moyennes des animes au fil des années\")\n",
    "plt.xlabel(\"Année\")\n",
    "plt.ylabel(\"Note moyenne\")\n",
    "plt.savefig(\"evolution_notes_moyennes_par_annee.png\")\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#8/La durée d'un épisode est généralement de 20 minutes (par expérience). \n",
    "#On veut vérifier si cette intuition est vraie. Pour cela, on réalise un histogramme.\n",
    "\n",
    "anime_data['average_episode_duration']=anime_data['average_episode_duration']/60\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(anime_data['average_episode_duration'].dropna(), bins=30, kde=True, color='purple')\n",
    "plt.title(\"Nbr d'animés en fonction de la durée moyenne de leurs épisodes\")\n",
    "plt.xlabel(\"Durée moyenne des épisodes (en minutes)\")\n",
    "plt.ylabel(\"Nbr d'animés\")\n",
    "\n",
    "x_ticks = np.arange(0, anime_data['average_episode_duration'].max() + 10, 5)  # de 0 à max+10 par pas de 5 minutes\n",
    "plt.xticks(x_ticks)\n",
    "\n",
    "plt.savefig(\"Nbr_animés_en_fct_durée_ep.png\")\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#9/On s'attend à ce que la plupart des animés ont 12 ou 24 épisodes. \n",
    "#Pour vérifier cette intuition, on fait un histogramme qui représente le nbr d'animés en fonction de leur nombres d'épisodes (si le nbr d'épisodes est de plus de 100, il ne sera pas représenté, car peu d'animés valident cette condition et ce sont des anomalies)\n",
    "\n",
    "anime_filtered = anime_data[anime_data['num_episodes'].between(1, 100)]\n",
    "\n",
    "episode_counts = anime_filtered['num_episodes'].value_counts().reindex(range(1, 101), fill_value=0).sort_index()\n",
    "\n",
    "plt.figure(figsize=(18, 8))\n",
    "sns.barplot(x=episode_counts.index, y=episode_counts.values, color='blue')\n",
    "\n",
    "plt.title(\"Nombre d'animés en fonction du nombre d'épisodes (1 à 100)\", fontsize=14)\n",
    "plt.xlabel(\"Nombre d'épisodes\", fontsize=12)\n",
    "plt.ylabel(\"Nombre d'animés\", fontsize=12)\n",
    "\n",
    "plt.xticks(ticks=range(1, 101, 5), labels=range(1, 101, 5), rotation=45)  # Ticks tous les 5 pour la lisibilité\n",
    "\n",
    "plt.savefig(\"nbr_animes_par_nombre_episodes_1_to_100.png\", dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"font-size: 22px; color: blue;\">3/Analyse de la popularité (la variable qui va être prédit à l'aide de notre classification) en fonction de diverses variables</h1>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1/Popularité en fonction des moyennes des notes\n",
    "#Lors de l'analyse exploratoire (notamment avec la matrice de corrélation), nous avons constaté une corrélation significative entre la popularité et les moyennes des notes.\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hexbin(x=df['mean'], y=df['popularity'], gridsize=50, cmap='Blues', mincnt=1)\n",
    "plt.colorbar(label='Count')\n",
    "plt.title('Popularité en fonction de la note moyenne')\n",
    "plt.xlabel('Note moyenne')\n",
    "plt.ylabel('Popularité')\n",
    "plt.show()\n",
    "plt.savefig('pop_en_fct_note_moyenne.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2/Popularité en fonction du nombre d'utilisateurs (qui ont regardé l'anime)\n",
    "#Nous cherchons à déterminer la nature de la relation entre le nombre d'utilisateurs et la popularité des animes, car il est logique de supposer que ces deux variables sont liées.\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(df['num_list_users'], df['popularity'], alpha=0.6, s=10)\n",
    "plt.xlim(0, df['num_list_users'].max())\n",
    "plt.title('Popularité en fonction du nombre d utilisateurs')\n",
    "plt.xlabel('num_list_users')\n",
    "plt.ylabel('Popularité')\n",
    "plt.yscale('log') #échelle logarithmique\n",
    "plt.show()\n",
    "plt.savefig('Popularité&nbr_users.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3/Popularité en fonction du type de média\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.boxplot(x=df['media_type'], y=df['popularity'], order=df['media_type'].value_counts().index)\n",
    "plt.title('Popularité en fonction du type de media')\n",
    "plt.xlabel('Media Type')\n",
    "plt.ylabel('Popularité')\n",
    "plt.yscale('log')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n",
    "plt.savefig('Popularité&type.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"font-size: 32px; color: green;\">Partie III : Modélisation et prédictions à partir des classifieurs</h1>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
